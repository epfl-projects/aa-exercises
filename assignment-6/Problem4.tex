% Extend a binary classifier to work with k classes
We propose the following two approaches to extending a binary classification algorithm to work with $k$ classes:

\begin{enumerate}
  \item ``One versus all'': run $k$ rounds of the learning algorithm, where at round $i$ we relabel the classes such that: $y_j\prime = 1$ if $y_j = i$, $y_k\prime = 0$ otherwise. Then we obtain two groups, one made only of class $i$, versus another constituted of all other classes. We train a classifier with this new dataset. At the end of $k$ rounds, we assign our data example to the class corresponding to the classifier which is most ``confidant''. Some classification algorithms (e.g. logistic regression) output a probability measure which can be used directly. In the case of the Perceptron algorithm, we could use for example the normalized margin which the data example achieved as a confidance measure.\\
  It is interesting to notice that in each round, the algorithm witnesses many more negative examples than positive examples, which might affect its performance.

  \item ``Binary search'': instead of running one group against all others, we can separate classes evenly, and recursively compare $\frac{k}{2}$ groups.
\end{enumerate}

The first approach requires $k$ runs, which may prove expensive with large datasets and dimensionality of the input. Approach 2, however, only requires $\Theta(\log_2(k))$ runs.

On the other hand, in real world applications, the dataset may very well include noise (e.g. mislabeled examples). The second approach is then more prone to misclassification, since it may eliminate the correct class early on in the process and never consider it again. The first approach would then be more resilient.
